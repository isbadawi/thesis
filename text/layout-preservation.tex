A refactoring is a code transformation that changes the structure of the code
while preserving its semantics, and can often naturally be thought of as a
transformation over the structure of an abstract syntax tree. However, from
the perspective of a programmer using a refactoring tool, a refactoring is
ultimately a textual transformation. It is important to reconcile these two
conceptions of refactorings; purely working in terms of ASTs, while
technically correct from a semantics perspective, is apt to lose a lot
of information about the textual layout of the code, while purely working
in terms of text is apt to make implementations of individual refactorings
very brittle, hard to reason about, and hard to maintain.

In this chapter, we present our approach to making refactorings layout
preserving.  We allow refactorings to be implemented in terms of a minimal tree
transformation API, which hides the mechanics of layout preservation. As
refactoring writers specify tree-level edits, minimal text-level edits are
transparently computed from them. This simplifies the implementations of
individual refactorings, allowing them to remain oblivious to the program text,
while making them directly usable by end-users.

\section{Motivation}

Once all the issues surrounding semantics-preservation -- running required
analyses, checking required preconditions, and so on -- are sorted out,
then from an implementation perspective, a refactoring is most
naturally thought of as a transformation on abstract syntax trees. For
instance, a refactoring like "extract method" can be boiled down to steps like
"move this statement from this function to that one", "synthesize a new
function call", and "replace that statement with this one", and so
on. Given this, a natural structure for a refactoring tool consists of parsing
code, then performing transformations on its AST, and then pretty printing the
transformed AST to retrieve source code to present to the programmer. Many
refactoring tools -- particularly ones developed for research purposes, where
practicality is often a non-goal -- operate this way.

The problem with such approaches is that by construction the AST does not
contain enough information to accurately reconstruct the input source code.
Typically among the casualties are whitespace, comments, and syntactic sugar.

\figref{Fig:LostLayout} shows a \matlab program and the result of parsing and
then pretty-printing it using the \mclab toolkit. The two programs are
behaviorally equivalent, but contain many syntactic differences. The comment
associated with the \code{cube} function has moved below the header. The
four-space indentation has been changed to two-space indentation. Each binary
expression has been wrapped in parentheses.  The output parameters have been
wrapped in square brackets.  The nested function \code{square} has been moved
-- in \matlab, nested functions have the same scope irrespective of where they
are declared; as a simplification, the Natlab translation moves nested
functions to the bottom of their enclosing function.

\begin{figure}
\begin{minipage}{0.5\linewidth}
\begin{lstlisting}[numbers=none]
% cube takes a number x and returns its cube.
function y = cube(x)
    % This is a nested function that computes the square of a value.
    function v = square(u)
        v = u * u;
    end
    y = x * square(x);
end
\end{lstlisting}
\end{minipage}
\hfill \hspace{.3cm} \hfill
\begin{minipage}{0.5\linewidth}
\begin{lstlisting}[numbers=none]
function [y] = cube(x)
  % cube takes a number x and returns its cube.
  % This is a nested function that computes the square of a value.
  y = (x * square(x));
  function [v] = square(u)
    v = (u * u);
  end
end
\end{lstlisting}
\end{minipage}
\caption{An example of the lossy parsing and unparsing roundtrip.}
\label{Fig:LostLayout}
\end{figure}

Users of an automated refactoring tool are unlikely to be accepting of such
invasive changes to a program's text. As such, it is important for the tool to
be aware of the layout of the program when performing refactorings. For a given
AST transformation, it should endeavor to perform the minimal textual changes
needed to reflect the transformation in the program text. In particular,
unaffected portions of the program should not undergo any textual changes.

Despite this, it is still convenient to express refactorings as tree
transformations. Refactorings would be much harder to implement and maintain if
they had to be expressed as textual transformations, or as a mixture of tree
and text transformations that had to be kept in sync.

Our goal is to be able to implement refactorings purely as tree
transformations, and to have minimal textual changes automatically computed
from them. In order to accomplish this, we introduce a simple transformation
API, which exposes a small set of tree manipulation operations. Instead of
directly manipulating AST nodes, refactorings are implemented in terms of this
API. Behind the scenes, the implementation of the API includes logic that keeps
track the input program text in addition to the AST, and keeps the two in sync.

\section{Synchronizing ASTs and token streams}

At a high level, our approach to layout preservation works as follows. Given a
\matlab source file, we start by tokenizing the source code using a \matlab
lexer, yielding a stream of tokens. Alongside the token stream, we use a
\matlab parser to parse the same source file, yielding an abstract syntax tree.
Our aim is to allow refactoring writers to specify edits to the abstract syntax
tree, and to have those edits be transparently reflected in the token stream.
In the end, when the time comes to present the transformed source back to the
user, we can simply concatenate all the tokens instead of pretty printing the
AST.

In order for this to work, there are two "primitives" that we rely on. First,
we need to be able to identify, for a particular AST node (which may be a node
from the original program, or a copy of a node, or a brand new synthesized
node), the portion of the token stream corresponding to that node. Second, we
need to be able to make local modifications to just that portion of the stream,
without compromising our ability to later look up nodes in the modified stream.

To bridge the gap between the token stream and the AST, we use position
information. Each token consists of a fragment of text together with a line and
column position where it occurs in the source code. Each AST node, assuming it
was produced by the parsing process and not manually synthesized after the
fact, also contains position information. As an initial link between the source
text and the AST, we can simply create a table that maps line and column
positions to the corresponding token in the stream. When we need to retrieve
the portion of the token stream for a given node, we can simply look up the
token corresponding to its start position, look up the node token corresponding
to its end position, and take all the tokens in between.

One potential complication here is that the mapping could become stale as the
token stream is modified. For instance, if we were to simply keep an array of
tokens and map positions to indices into the array, then as the stream is
edited and tokens are shifted around, indices would no longer point to the same
token. In some cases we may be able to update the mapping as we edit the
stream, but that approach quickly becomes brittle and hard to reason about.

In order to avoid this complication, and also to satisfy our requirement of
supporting local edits to the token stream, it is necessary to carefully
consider the data structure we will use to represent the token stream. A
natural choice is a doubly linked list. The values in our table can be
references to individual nodes in the list, which will remain valid even as
their positions within the list change. Also, since each node contains a
reference to its predecessor and successor within the list, we can cheaply
support edits like removing a sequence of tokens, or inserting a sequence of
tokens before or after a particular token.

A common operation when implementing refactorings is to a copy an AST
node. Since this approach associates mutable state (a portion of the token
stream) with each node, it's not enough to simply copy the node; the
corresponding token stream fragment should be also be copied, and the copy
associated with the newly copied node. We will see later that `copy(ASTNode)`
is an operation exposed by the transformation API.

That suffices for correlating the token stream with the AST of the original
source text, but we need to be able to maintain this mapping as the token
stream is edited, code is moved around or copied, and new code is synthesized.

\section{Dealing with freshly synthesized code}

It is common for refactorings to insert new code into the program which wasn't
present in the original source text. For example, in the case of extract
method, a new function call is synthesized to replace the extracted statements,
a new function is synthesized to hold them, and that new function might also
contain some synthetic statements like global variable declarations to ensure
semantics are preserved. These pose a problem since there is no original text
to tokenize in this case.

The natural intuition is to somehow leverage the output of the pretty printer
to recover some text that we may integrate into the token stream. If we simply
pretty print the new AST, we get a program fragment as a string that we can
then feed to the lexer. However, since these synthetic AST nodes don't have
position information, we can't easily associate nodes with their portion of the
token stream. We can associate the top-level tree with the entire fragment, but
subtrees pose a problem.

One way to deal with this would be to pretty print the new AST to recover the
program text, then parse the text again to get back an AST that has position
information, and then proceed as before. This is viable, but it implies that
all new nodes would have to be synthesized through the tree transformation API
-- nodes that are synthesized by the caller directly couldn't be used, since
they wouldn't have the necessary position information.

In the interest of keeping the API surface small, we instead implement a
tokenizing pretty printer, which is a version of the pretty printer that emits
sequences of tokens instead of entire strings. This can implemented as a
straightforward recursive traversal of the AST; for each node, we synthesize a
sequence of tokens, and at the same time associate that sequence with the node
for later use.

Given this facility, the procedure for looking up a given node's portion of the
a token stream becomes:

\begin{enumerate}
  \item If it has a token stream fragment associated with it, return it.
  \item If it is synthetic, then synthesize a token stream fragment using the
  tokenizing pretty printer, associate it with the node and return it
  \item Otherwise look it up in the original mapping using its position information.
\end{enumerate}

\section{The transformation API}

All AST manipulation can be boiled down to a series of node deletions and
insertions.  A replace operation is also convenient, and as mentioned
previously a copy operation is required by our approach to layout preservation.
Finally, an operation to recover the transformed source code is also needed.
\figref{Fig:TransformerAPI} shows how these operations are encoded as a Java
interface, and \figref{Fig:BasicTransformer} shows a trivial implementation of
the interface that just falls back on AST operations, ignoring layout concerns.

\begin{figure}
\begin{lstlisting}[numbers=none, language=Java]
public interface Transformer {
  void replace(ASTNode<?> node, ASTNode<?> newNode);
  void remove(ASTNode<?> node);
  void insert(ASTNode<?> node, ASTNode<?> newNode, int i);
  <T extends ASTNode<?>> T copy(T node);
  String reconstructText();
}
\end{lstlisting}
\caption{The Transformer API, encoded as a Java interface}
\label{Fig:TransformerAPI}
\end{figure}

\begin{figure}
\begin{lstlisting}[numbers=none, language=Java]
public class BasicTransformer implements Transformer {
  private Program program;

  public BasicTransformer(Program program) {
    this.program = program;
  }

  public void replace(ASTNode<?> node, ASTNode<?> newNode) {
    node.getParent().setChild(newNode, node.getParent().getIndexOfChild(node));
  }

  public void remove(ASTNode<?> node) {
    node.getParent().removeChild(node.getParent().getIndexOfChild(node));
  }

  public void insert(ASTNode<?> node, ASTNode<?> newNode, int i) {
    node.insertChild(newNode, i);
  }

  public <T extends ASTNode<?>> T copy(T node) {
    return (T) node.fullCopy();
  }

  public String reconstructText() {
    return program.getPrettyPrinted();
  }
}
\end{lstlisting}
\caption{A trivial implementation of the Transformer API}
\label{Fig:BasicTransformer}
\end{figure}

\section{Case studies: inline variable, extract function}

The Inline Variable refactoring is relatively simple; it takes an assignment
statement as input, and replaces each use of the assigned variable with the
expression on the right hand side before removing the assignment.
\figref{Fig:InlineVariable} shows how the mechanics of the transformation are
implemented against the transformation API (skipping over the portions of the
code dealing with the correctness of the transformation).

\begin{figure}
\begin{lstlisting}[numbers=none, language=Java]
public class InlineVariable extends Refactoring {
  private AssignStmt definition;

  // constructors, correctness checks, ...

  public void apply() {
    Transformer transformer = context.getTransformer(definition);
    UseDefDefUseChain udduChain = definition.getMatlabProgram().analyze().getUseDefDefUseChain();
    for (Name name : udduChain.getUses(definition)) {
      transformer.replace(name.getParent(), transformer.copy(definition.getRHS()));
    }
    transformer.remove(definition);
  }
}
\end{lstlisting}
\caption{The implementation of the Inline Variable refactoring using the transformer API}
\label{Fig:InlineVariable}
\end{figure}

The Extract Function refactoring slightly more involved.
\figref{Fig:ExtractFunction} shows how the mechanics of the transformations are
implemented against the transformation API. Even though the refactoring moves
AST nodes around, copies nodes, and mixes in synthetic code with the original text,
the code is completely oblivious to text, instead leaning on the {\tt Transformer}
to do the heavy lifting.

\begin{figure}
\begin{lstlisting}[numbers=none, language=Java]
public class ExtractFunction extends Refactoring {
  private StatementRange extractionRange;
  private Function enclosingFunction;
  private String extractedFunctionName;

  // constructors, correctness checks, ...

  // Synthesizes a call to the extracted function. Since there is no
  // code to preserve, it doesn't use the transformation API.
  private Stmt makeCallToExtractedFunction() { /* ... */ }
  // Determines the extracted function's input parameters
  private List<String> inputVars() { /* ... */ }
  // Determines the extracted function's output parameters
  private List<String> outputVars() { /* ... */ }
  // Determines the global variables used by the extracted function
  private List<String> globalVars() { /* ... */ }

  public void apply() {
    Transformer transformer = context.getTransformer(enclosingFunction);
    Function extracted = new Function(extractedFunctionName);
    for (Stmt stmt : extractionRange) {
      transformer.insert(extracted.getStmts(), transformer.copy(stmt), extracted.getNumStmt());
    }

    extracted.addInputParams(inputVars());
    extracted.addOutputParams(outputVars());
    for (String var : globalVars()) {
      transformer.insert(extracted.getStmts(), new GlobalStmt(var), 0);
    }

    List<Function> functionList = ((FunctionList) enclosingFunction.getParent()).getFunctions();
    transformer.insert(functionList, extracted, functionList.getIndexOfChild(enclosingFunction) + 1);
    for (int i = 0; i < extractionRange.size(); ++i) {
      transformer.remove(extractionRange.getStartStatement());
    }
    transformer.insert(extractionRange.getEnclosingStatementList(),
      makeCallToExtractedFunction(), extractionRange.getStartIndex());
  }
}
\end{lstlisting}
\caption{The implementation of the Extract Function refactoring using the transformer API}
\label{Fig:ExtractFunction}
\end{figure}

\section{Related work}

The work that most closely resembles ours is HaRe, a refactoring tool for
Haskell \cite{HaRe}. It uses a similar approach of synchronizing an AST with a
token stream, which is then concatenated to produce transformed source code.

Waddington and Yao \cite{Proteus} tackled the same problem, which they termed
"the problem of style disruption", with Proteus, their refactoring tool for C
and C++. Their approach was to use a specialized AST called a "Literal-Layout
AST (LL-AST)", where literals, token and whitespace nodes are interspersed
alongside the regular nodes. Enhancing the AST with layout information has also
been the theme of a few other approaches to this problem \cite{RefactorErl}.

% TODO(isbadawi): Look at how http://scala-refactoring.org/ does it
% TODO(isbadawi): Look at "An Algorithm for Layout Preservation in Refactoring Transformations"
% TODO(isbadawi): Look at "Detaching and Reconstructing the Documentary Structure of Source Code" (looks iffy)

The Eclipse JDT contains infrastructure for modifying code at two levels -- a
lower-level API for describing text manipulation primitives, and a higher-level
AST rewriting API, which accepts descriptions of changes to AST nodes and uses
the text manipulation API to try and perform the textual changes required to
represent the AST changes. The approach is similar to ours in spirit; one big
difference is that since that our approach is implemented largely as a
standalone tool, we rely solely on lexing and parsing as primitives, while
Eclipse's implementation benefits from more sophisticated integration with a
scriptable text editor.
